# Bandit-Algorithms-for-Sequential-Decision-Making

I implemented a range of multi-armed bandit algorithms, including variants of Upper Confidence Bound, KL-UCB, and Thompson Sampling, to evaluate and compare their performance across diverse bandit scenarios. I developed a novel algorithm leveraging Bayesian techniques to address faulty bandits, effectively maximizing cumulative rewards. Additionally, I designed a Thompson Sampling variant tailored for multi-multi bandit problems, optimizing arm selection in dynamic and complex scenarios.

